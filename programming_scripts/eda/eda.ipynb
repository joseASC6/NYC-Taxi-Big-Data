{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "from datetime import datetime, date\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, isnan, when, count, udf, to_date, year, month, date_format, size, split, dayofweek\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'my-bigdataproject-jg'\n",
    "gs_path  = f'gs://{bucket_name}/'\n",
    "landing_folder = 'landing/'\n",
    "cleaned_folder = 'cleaned/'\n",
    "destination_folder = 'code_and_models/'\n",
    "\n",
    "storage_client = storage.Client() \n",
    "bucket = storage_client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "    .appName(\"Taxi Demand Prediction\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_files = gs_path + landing_folder + 'weather_data_*.csv'\n",
    "weather_df = spark.read.csv(weather_files, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_files = gs_path + landing_folder + 'yellow_tripdata_2023-*.parquet'\n",
    "taxi_df = spark.read.parquet(taxi_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Column names\n",
    "DataTypes\n",
    "\n",
    "VendorID\n",
    "long\n",
    "\n",
    "tpep_pickup_datetime\n",
    "timestamp_ntz\n",
    "\n",
    "tpep_dropoff_datetime\n",
    "timestamp_ntz\n",
    "\n",
    "passenger_count\n",
    "double\n",
    "\n",
    "trip_distance\n",
    "double\n",
    "\n",
    "RatecodeID\n",
    "double\n",
    "\n",
    "store_and_fwd_flag\n",
    "string\n",
    "\n",
    "PULocationID\n",
    "long\n",
    "\n",
    "DOLocationID\n",
    "long\n",
    "\n",
    "payment_type\n",
    "long\n",
    "\n",
    "fare_amount\n",
    "double\n",
    "\n",
    "extra\n",
    "double\n",
    "\n",
    "mta_tax\n",
    "double\n",
    "\n",
    "tip_amount\n",
    "double\n",
    "\n",
    "tolls_amount\n",
    "double\n",
    "\n",
    "improvement_surcharge\n",
    "double\n",
    "\n",
    "total_amount\n",
    "double\n",
    "\n",
    "congestion_surcharge\n",
    "double\n",
    "\n",
    "airport_fee\n",
    "double\n",
    "\"\"\"\n",
    "\n",
    "# Check the min and max dates for the two columns: tpep_pickup_datetime and tpep_dropoff_datetime\n",
    "taxi_df.select(F.min('tpep_pickup_datetime'), F.max('tpep_pickup_datetime')).show()\n",
    "taxi_df.select(F.min('tpep_dropoff_datetime'), F.max('tpep_dropoff_datetime')).show()\n",
    "\n",
    "# Only keep the records within the date range: 2021-01-01 to 2024-01-01\n",
    "\n",
    "taxi_df = taxi_df.filter((col('tpep_pickup_datetime') >= '2021-01-01') & (col('tpep_pickup_datetime') < '2024-01-01'))\n",
    "taxi_df = taxi_df.filter((col('tpep_dropoff_datetime') >= '2021-01-01') & (col('tpep_dropoff_datetime') < '2024-01-01'))\n",
    "\n",
    "# Check the min and max dates for the two columns: tpep_pickup_datetime and tpep_dropoff_datetime\n",
    "taxi_df.select(F.min('tpep_pickup_datetime'), F.max('tpep_pickup_datetime')).show()\n",
    "taxi_df.select(F.min('tpep_dropoff_datetime'), F.max('tpep_dropoff_datetime')).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column for trip duration in minutes\n",
    "# first convert the tpep_pickup_datetime and tpep_dropoff_datetime to unix timestamp\n",
    "taxi_df = taxi_df.withColumn('pickup_unix', F.unix_timestamp('tpep_pickup_datetime'))\n",
    "taxi_df = taxi_df.withColumn('dropoff_unix', F.unix_timestamp('tpep_dropoff_datetime'))\n",
    "\n",
    "# calculate the trip duration in minutes\n",
    "taxi_df = taxi_df.withColumn('trip_duration', (col('dropoff_unix') - col('pickup_unix')) / 60)\n",
    "\n",
    "# describe the trip duration\n",
    "taxi_df.select('trip_duration').describe().show()\n",
    "\n",
    "# show me the columns where trip duration is less than 0\n",
    "taxi_df.filter(col('trip_duration') < 0).select('tpickup_datetime', 'tpep_dropoff_datetime', 'trip_duration').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a graph of the number of trips per week from 2021 to 2023 (based on tpep_pickup_datetime)\n",
    "# Create a new column: week_of_year\n",
    "taxi_df = taxi_df.withColumn('week_of_year', F.weekofyear('tpep_pickup_datetime'))\n",
    "\n",
    "# Group by week_of_year and count the number of trips\n",
    "trips_per_week = taxi_df.groupBy('week_of_year').count().orderBy('week_of_year')\n",
    "\n",
    "# Convert the spark dataframe to pandas dataframe\n",
    "trips_per_week_pd = trips_per_week.toPandas()\n",
    "\n",
    "# Plot the graph\n",
    "trips_per_week_pd.plot(x='week_of_year', y='count', kind='line', figsize=(15, 6), title='Number of trips per week from 2021 to 2023')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
