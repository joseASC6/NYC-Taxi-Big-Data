{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "from datetime import datetime, date\n",
    "\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, isnan, when, count, udf, to_date, year, month, date_format, size, split, dayofweek\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler, MinMaxScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'my-bigdataproject-jg'\n",
    "gs_path  = f'gs://{bucket_name}/'\n",
    "cleaned_folder = 'cleaned/'\n",
    "destination_folder = 'code_and_models/'\n",
    "\n",
    "storage_client = storage.Client() \n",
    "bucket = storage_client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "    .appName(\"Taxi Demand Prediction\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_files = gs_path + cleaned_folder + \"yellow_tripdata_*.parquet\"\n",
    "taxi_df = spark.read.parquet(taxi_files)\n",
    "taxi_df.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = taxi_df.drop('__index_level_0__')\n",
    "taxi_df = taxi_df.drop('dropoff_datetime')\n",
    "taxi_df = taxi_df.drop('DOLocationID')\n",
    "taxi_df = taxi_df.withColumn('pickup_datetime', to_date(col('pickup_datetime')))\n",
    "\n",
    "taxi_df.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone_file = gs_path + cleaned_folder + 'taxi_zones_data.csv'\n",
    "taxi_zone_df = spark.read.parquet(taxi_zone_file)\n",
    "\n",
    "taxi_df.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = taxi_df.join(taxi_zone_df, taxi_df.PULocationID == taxi_zone_df.LocationID)\n",
    "taxi_df = taxi_df.drop('zone')\n",
    "taxi_df = taxi_df.drop('PULocationID')\n",
    "taxi_df = taxi_df.drop('LocationID')\n",
    "taxi_df.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.createOrReplaceTempView('taxi_df')\n",
    "taxi_df = spark.sql('SELECT pickup_datetime, borough, COUNT(*) as total_trips FROM taxi_df GROUP BY pickup_datetime, borough')\n",
    "taxi_df = taxi_df.dropna(subset=['total_trips'])\n",
    "taxi_df = taxi_df.filter(taxi_df.borough != 'EWR')\n",
    "taxi_df.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the data\n",
    "\n",
    "# Convert the Spark DataFrame to a Pandas DataFrame\n",
    "taxi_df_pd = taxi_df.toPandas()\n",
    "\n",
    "# Show a histogram of the total trips for each borough\n",
    "taxi_df_pd.hist(column='total_trips', by='borough', bins=30, figsize=(15, 10))\n",
    "\n",
    "# Show a historgam of the total trips for the entire dataset by date\n",
    "taxi_df_pd['pickup_datetime'] = pd.to_datetime(taxi_df_pd['pickup_datetime'])\n",
    "taxi_df_pd.set_index('pickup_datetime', inplace=True)\n",
    "taxi_df_pd['total_trips'].plot(figsize=(15, 10))3\n",
    "\n",
    "# Show a histogram of the total trips for the entire dataset by month\n",
    "taxi_df_pd['month'] = taxi_df_pd.index.month\n",
    "taxi_df_pd['year'] = taxi_df_pd.index.year\n",
    "taxi_df_pd.groupby(['year', 'month'])['total_trips'].sum().plot(kind='bar', figsize=(15, 10))\n",
    "\n",
    "# Show a histogram of the daily trips for september 2023\n",
    "taxi_df_pd['day'] = taxi_df_pd.index.day\n",
    "taxi_df_pd['year'] = taxi_df_pd.index.year\n",
    "taxi_df_pd['month'] = taxi_df_pd.index.month\n",
    "taxi_df_pd[(taxi_df_pd['year'] == 2023) & (taxi_df_pd['month'] == 9)].groupby('day')['total_trips'].sum().plot(kind='bar', figsize=(15, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the total trips for each borough in all years\n",
    "taxi_df_pd.groupby('borough')['total_trips'].describe()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
