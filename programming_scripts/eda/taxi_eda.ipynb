{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "from datetime import datetime, date\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, BooleanType, IntegerType , DateType, FloatType, StructType, StructField\n",
    "from pyspark.sql.functions import col, isnan, when, count, udf, to_date, year, month, date_format, size, split, dayofweek\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'my-bigdataproject-jg'\n",
    "gs_path  = f'gs://{bucket_name}/'\n",
    "landing_folder = 'landing/'\n",
    "cleaned_folder = 'cleaned/'\n",
    "destination_folder = 'code_and_models/'\n",
    "\n",
    "storage_client = storage.Client() \n",
    "bucket = storage_client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "    .appName(\"Taxi Demand Prediction\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_years = [2023]\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "taxi_file_path = gs_path + landing_folder\n",
    "taxi_file_list = [taxi_file_path + f'yellow_tripdata_{year}-{month}.parquet' for year in data_years for month in months]\n",
    "\n",
    "taxi_df = None\n",
    "for file in taxi_file_list:\n",
    "    df = spark.read.parquet(file)\n",
    "    df = df.withColumn('VendorID', df['VendorID'].cast(IntegerType()))\n",
    "    df = df.withColumn('passenger_count', df['passenger_count'].cast(IntegerType()))\n",
    "    if taxi_df is None:\n",
    "        taxi_df = df\n",
    "    else:\n",
    "        taxi_df = taxi_df.union(df)\n",
    "\n",
    "taxi_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of records in the dataframe: {taxi_df.count():,}')\n",
    "print(f'Number of columns in the dataframe: {len(taxi_df.columns)}')\n",
    "\n",
    "taxi_df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empty Recoreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.select([count(when(col(c).isNull(), c)).alias(c) for c in taxi_df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passenger_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.select('passenger_count').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.groupBy('passenger_count').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the passenger_count column to show the distribution of the number of passengers\n",
    "passenger_count_df = taxi_df.groupBy('passenger_count').count().toPandas()\n",
    "passenger_count_df = passenger_count_df.sort_values(by='passenger_count')\n",
    "passenger_count_df.plot(kind='bar', x='passenger_count', y='count', color='blue', figsize=(10, 6))\n",
    "plt.title('Distribution of the number of passengers')\n",
    "plt.xlabel('Number of passengers')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "for i, count in enumerate(passenger_count_df['count']):\n",
    "    plt.text(i, count, f'{count:,}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Column names\n",
    "DataTypes\n",
    "\n",
    "VendorID\n",
    "long\n",
    "\n",
    "tpep_pickup_datetime\n",
    "timestamp_ntz\n",
    "\n",
    "tpep_dropoff_datetime\n",
    "timestamp_ntz\n",
    "\n",
    "passenger_count\n",
    "double\n",
    "\n",
    "trip_distance\n",
    "double\n",
    "\n",
    "RatecodeID\n",
    "double\n",
    "\n",
    "store_and_fwd_flag\n",
    "string\n",
    "\n",
    "PULocationID\n",
    "long\n",
    "\n",
    "DOLocationID\n",
    "long\n",
    "\n",
    "payment_type\n",
    "long\n",
    "\n",
    "fare_amount\n",
    "double\n",
    "\n",
    "extra\n",
    "double\n",
    "\n",
    "mta_tax\n",
    "double\n",
    "\n",
    "tip_amount\n",
    "double\n",
    "\n",
    "tolls_amount\n",
    "double\n",
    "\n",
    "improvement_surcharge\n",
    "double\n",
    "\n",
    "total_amount\n",
    "double\n",
    "\n",
    "congestion_surcharge\n",
    "double\n",
    "\n",
    "airport_fee\n",
    "double\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the min and max dates for the two columns: tpep_pickup_datetime and tpep_dropoff_datetime\n",
    "taxi_df.select(F.min('tpep_pickup_datetime'), F.max('tpep_pickup_datetime')).show()\n",
    "taxi_df.select(F.min('tpep_dropoff_datetime'), F.max('tpep_dropoff_datetime')).show()\n",
    "\n",
    "# Only keep the records within the date range: 2021-01-01 to 2024-01-01\n",
    "\n",
    "taxi_df = taxi_df.filter((col('tpep_pickup_datetime') >= '2021-01-01') & (col('tpep_pickup_datetime') < '2024-01-01'))\n",
    "taxi_df = taxi_df.filter((col('tpep_dropoff_datetime') >= '2021-01-01') & (col('tpep_dropoff_datetime') < '2024-01-01'))\n",
    "\n",
    "# Check the min and max dates for the two columns: tpep_pickup_datetime and tpep_dropoff_datetime\n",
    "taxi_df.select(F.min('tpep_pickup_datetime'), F.max('tpep_pickup_datetime')).show()\n",
    "taxi_df.select(F.min('tpep_dropoff_datetime'), F.max('tpep_dropoff_datetime')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column for trip duration in minutes\n",
    "# first convert the tpep_pickup_datetime and tpep_dropoff_datetime to unix timestamp\n",
    "taxi_df = taxi_df.withColumn('pickup_unix', F.unix_timestamp('tpep_pickup_datetime'))\n",
    "taxi_df = taxi_df.withColumn('dropoff_unix', F.unix_timestamp('tpep_dropoff_datetime'))\n",
    "\n",
    "# calculate the trip duration in minutes\n",
    "taxi_df = taxi_df.withColumn('trip_duration', (col('dropoff_unix') - col('pickup_unix')) / 60)\n",
    "\n",
    "# describe the trip duration\n",
    "taxi_df.select('trip_duration').describe().show()\n",
    "\n",
    "# show me the columns where trip duration is less than 0\n",
    "taxi_df.filter(col('trip_duration') < 0).select('tpickup_datetime', 'tpep_dropoff_datetime', 'trip_duration').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a graph of the number of trips per week from 2021 to 2023 (based on tpep_pickup_datetime)\n",
    "# Create a new column: week_of_year\n",
    "taxi_df = taxi_df.withColumn('week_of_year', F.weekofyear('tpep_pickup_datetime'))\n",
    "\n",
    "# Group by week_of_year and count the number of trips\n",
    "trips_per_week = taxi_df.groupBy('week_of_year').count().orderBy('week_of_year')\n",
    "\n",
    "# Convert the spark dataframe to pandas dataframe\n",
    "trips_per_week_pd = trips_per_week.toPandas()\n",
    "\n",
    "# Plot the graph\n",
    "trips_per_week_pd.plot(x='week_of_year', y='count', kind='line', figsize=(15, 6), title='Number of trips per week from 2021 to 2023')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
