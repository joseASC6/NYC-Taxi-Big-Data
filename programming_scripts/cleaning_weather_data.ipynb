{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs = ['Manhattan', 'Brooklyn']\n",
    "years = [2021, 2022, 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'my-bigdataproject-jg'\n",
    "gs_path  = f'gs://{bucket_name}/'\n",
    "storage_client = storage.Client() \n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "cleaned_folder = 'cleaned/'\n",
    "landing_folder = 'landing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(borough, year):\n",
    "    print(f'Getting data for {borough} in {year}')\n",
    "    file_name = f'weather_data_{borough}_{year}.csv'\n",
    "    file_path = f'{landing_folder}{file_name}'\n",
    "    blob = bucket.blob(file_path)\n",
    "    blob.download_to_filename(file_name)\n",
    "    df = pd.read_csv(file_name)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, borough, year):\n",
    "    print('Cleaning data')\n",
    "    # Keep only the columns we need\n",
    "    df = df[['name', 'datetime', 'tempmax', 'tempmin', 'temp', 'feelslikemax', 'feelslikemin', 'feelslike', 'humidity', 'precip', 'preciptype', 'snow', 'snowdepth', 'windspeed', 'cloudcover', 'visibility', 'uvindex', 'sunrise', 'sunset', 'conditions']].copy()\n",
    "\n",
    "    # Fill in the rows with missing precip type to 'None'\n",
    "    df['preciptype'] = df['preciptype'].fillna('None')\n",
    "\n",
    "    # Set the data types\n",
    "    # Set to datetime\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df['sunrise'] = pd.to_datetime(df['sunrise'])\n",
    "    df['sunset'] = pd.to_datetime(df['sunset'])\n",
    "\n",
    "    # Set to string\n",
    "    df['name'] = df['name'].astype('string')\n",
    "    df['preciptype'] = df['preciptype'].astype('string')\n",
    "    df['conditions'] = df['conditions'].astype('string')\n",
    "\n",
    "    # Set to double\n",
    "    df['tempmax'] = df['tempmax'].astype('float64')\n",
    "    df['tempmin'] = df['tempmin'].astype('float64')\n",
    "    df['temp'] = df['temp'].astype('float64')\n",
    "    df['feelslikemax'] = df['feelslikemax'].astype('float64')\n",
    "    df['feelslikemin'] = df['feelslikemin'].astype('float64')\n",
    "    df['feelslike'] = df['feelslike'].astype('float64')\n",
    "    df['humidity'] = df['humidity'].astype('float64')\n",
    "    df['precip'] = df['precip'].astype('float64')\n",
    "    df['snow'] = df['snow'].astype('float64')\n",
    "    df['snowdepth'] = df['snowdepth'].astype('float64')\n",
    "    df['windspeed'] = df['windspeed'].astype('float64')\n",
    "    df['cloudcover'] = df['cloudcover'].astype('float64')\n",
    "    df['visibility'] = df['visibility'].astype('float64')\n",
    "\n",
    "    # Set to int\n",
    "    df['uvindex'] = df['uvindex'].astype('Int64')\n",
    "\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    df = df.dropna()\n",
    "    print('Data cleaned')\n",
    "\n",
    "    # Upload cleaned data to GCS as a Parquet file\n",
    "    file_name = f'weather_data_{borough}_{year}.parquet'\n",
    "    file_path = f'{cleaned_folder}{file_name}'\n",
    "    print(f'Uploading:\\t {file_path}')\n",
    "    df.to_parquet(file_name)\n",
    "    blob = bucket.blob(file_path)\n",
    "    blob.upload_from_filename(file_name)\n",
    "    print('Data uploaded')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print('Starting data cleaning')\n",
    "    for borough in boroughs:\n",
    "        for year in years:\n",
    "            df = get_data(borough, year)\n",
    "            clean_data(df, borough, year)\n",
    "    print('Data cleaning complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
